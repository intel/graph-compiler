################################################################################
# Copyright 2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

from . import util, gapi, ops
from .ops import op
import torch
from typing import Dict, List, Set


class Graph:

    # tensor id -> logical tensor definition from the graph
    logical_tensors: Dict[int, gapi.LogicalTensor]

    tensors: Dict[int, torch.Tensor]

    # op id -> op definition
    ops: Dict[int, gapi.Op]
    # op list in topological order
    topo_ops: List[gapi.Op]

    exec_ops: Dict[int, op.Op]

    # record all graph input tensors
    in_tensors: Set[int]
    # record all graph output tensors
    out_tensors: Set[int]

    # checkers for each output tensor
    checkers: Dict[int, util.Checker]

    def __init__(self, graph: gapi.Graph):

        self.logical_tensors = {}
        self.tensors = {}
        self.ops = {}
        self.topo_ops = []
        self.exec_ops = {}
        self.in_tensors = set()
        self.out_tensors = set()
        self.checkers = {}

        self.in_lt_2_op: Dict[int, List[int]] = {}
        in_tensor_to_ops: Dict[int, List[int]] = {}
        out_tensor_to_op: Dict[int, int] = {}
        op_in_deg: Dict[int, int] = {}

        for op in graph.graph:
            if op.kind == "End":
                # treat the input of end op as output tensor
                self.out_tensors.add(op.inputs[0].id)
                # ignore END op
                continue

            self.ops[op.id] = op
            # find the op class by its kind and then create the object
            self.exec_ops[op.id] = ops.f[op.kind](op)
            op_in_deg[op.id] = len(op.inputs)
            # create tensor buffer for each tensor
            for i in op.inputs:
                self.logical_tensors[i.id] = i
                if i.id not in in_tensor_to_ops:
                    in_tensor_to_ops[i.id] = [op.id]
                else:
                    in_tensor_to_ops[i.id].append(op.id)
            for o in op.outputs:
                self.logical_tensors[o.id] = o
                out_tensor_to_op[o.id] = op.id

        for id in self.logical_tensors:
            # this tensor is not generated by other op
            # treat it as graph input
            if id not in out_tensor_to_op:
                self.in_tensors.add(id)
                # remove input degree
                for op_id in in_tensor_to_ops[id]:
                    op_in_deg[op_id] -= 1
                    # if input degree of this op is zero
                    # append the op to the topo order list
                    if op_in_deg[op_id] == 0:
                        self.topo_ops.append(self.ops[op_id])
            # this tensor is never cosumed by other op
            # treat it as graph output
            if id not in in_tensor_to_ops:
                self.out_tensors.add(id)

        topo_idx: int = 0
        while topo_idx < len(self.topo_ops):
            # enumerate the output tensor of current id
            # decrease the input degree of consumer op
            # if the input degree decreases to zero
            # append to topo list
            for tensor in self.topo_ops[topo_idx].outputs:
                if tensor.id not in in_tensor_to_ops:
                    continue
                for op_id in in_tensor_to_ops[tensor.id]:
                    op_in_deg[op_id] -= 1
                    if op_in_deg[op_id] == 0:
                        self.topo_ops.append(self.ops[op_id])
            topo_idx += 1

        # generate checkers for each output tensor
        for id in self.ops:
            for i in range(len(self.ops[id].outputs)):
                out = self.ops[id].outputs[i]
                if out.id in self.out_tensors:
                    self.checkers[out.id] = self.exec_ops[id].checker(i)
        self.in_lt_2_op = in_tensor_to_ops

    def prepare_input(self, verbose: int):
        for _, v in self.exec_ops.items():
            # For a single op, fill all input tensors of this OP
            res: Dict[int, torch.Tensor] = v.fill_data()
            # Update self.in_tensors
            for tid in res.keys():
                if tid in self.in_tensors:
                    # Udpate stride to the original stride in JSON
                    stride: List[int] = self.logical_tensors[tid].stride
                    res[tid] = res[tid].as_strided(size=res[tid].shape, stride=stride)
                    self.tensors.update({tid: res[tid]})
        if verbose >= util.INPUT_VERBOSE:
            print(f"self.tensors: {self.tensors}")
